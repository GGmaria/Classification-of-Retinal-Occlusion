{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LN0R4hFDPqEb"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36428,"status":"ok","timestamp":1684839301186,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"xLbt8N0EPtjp","outputId":"0271a95d-0dcd-47b2-d173-057fe53f5688"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6544,"status":"ok","timestamp":1684839570239,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"OL_oHlC9Qy-S","outputId":"b9b957eb-d69b-4160-f662-f3167310d86d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80134624/80134624 [==============================] - 3s 0us/step\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," dense (Dense)               (None, 256)               6422784   \n","                                                                 \n"," dense_1 (Dense)             (None, 128)               32896     \n","                                                                 \n"," dense_2 (Dense)             (None, 4)                 516       \n","                                                                 \n","=================================================================\n","Total params: 26,480,580\n","Trainable params: 6,456,196\n","Non-trainable params: 20,024,384\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras.applications.vgg19 import VGG19\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.models import Model\n","\n","# Load the pre-trained VGG19 model\n","vgg = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# Freeze the layers in the pre-trained model\n","for layer in vgg.layers:\n","    layer.trainable = False\n","\n","# Add a new classification head on top of the pre-trained model\n","x = Flatten()(vgg.output)\n","x = Dense(256, activation='relu')(x)\n","x = Dense(128, activation='relu')(x)\n","output = Dense(4, activation='softmax')(x)\n","\n","# Create the new model\n","model = Model(inputs=vgg.input, outputs=output)\n","\n","# Print the summary of the model\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5077422,"status":"ok","timestamp":1684850062237,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"0JmxLla5RHLp","outputId":"0014ba03-8bc6-419f-913f-df7a1b58fcfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 695 images belonging to 4 classes.\n","Found 91 images belonging to 4 classes.\n","Found 93 images belonging to 4 classes.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","22/22 [==============================] - 486s 22s/step - loss: 3.2664 - accuracy: 0.5079 - val_loss: 0.6624 - val_accuracy: 0.7363\n","Epoch 2/10\n","22/22 [==============================] - 483s 22s/step - loss: 0.5342 - accuracy: 0.7871 - val_loss: 0.6901 - val_accuracy: 0.7692\n","Epoch 3/10\n","22/22 [==============================] - 455s 21s/step - loss: 0.3483 - accuracy: 0.8719 - val_loss: 0.3981 - val_accuracy: 0.8791\n","Epoch 4/10\n","22/22 [==============================] - 496s 23s/step - loss: 0.2530 - accuracy: 0.9137 - val_loss: 0.5428 - val_accuracy: 0.8571\n","Epoch 5/10\n","22/22 [==============================] - 465s 21s/step - loss: 0.2927 - accuracy: 0.8935 - val_loss: 0.6516 - val_accuracy: 0.7033\n","Epoch 6/10\n","22/22 [==============================] - 494s 23s/step - loss: 0.2496 - accuracy: 0.9137 - val_loss: 0.3692 - val_accuracy: 0.9011\n","Epoch 7/10\n","22/22 [==============================] - 495s 23s/step - loss: 0.1087 - accuracy: 0.9698 - val_loss: 0.3871 - val_accuracy: 0.9341\n","Epoch 8/10\n","22/22 [==============================] - 492s 23s/step - loss: 0.1840 - accuracy: 0.9367 - val_loss: 0.3834 - val_accuracy: 0.8681\n","Epoch 9/10\n","22/22 [==============================] - 462s 21s/step - loss: 0.1216 - accuracy: 0.9626 - val_loss: 0.3957 - val_accuracy: 0.9121\n","Epoch 10/10\n","22/22 [==============================] - 467s 21s/step - loss: 0.1707 - accuracy: 0.9468 - val_loss: 0.5177 - val_accuracy: 0.7692\n","3/3 [==============================] - 54s 18s/step - loss: 0.5681 - accuracy: 0.7097\n","Test loss: 0.5680665969848633\n","Test accuracy: 0.7096773982048035\n","3/3 [==============================] - 55s 18s/step\n","              precision    recall  f1-score   support\n","\n","        Brvo       0.60      0.55      0.57        53\n","        Crvo       0.24      0.35      0.29        20\n","      Normal       0.30      0.25      0.27        12\n","         Rao       0.17      0.12      0.14         8\n","\n","    accuracy                           0.43        93\n","   macro avg       0.33      0.32      0.32        93\n","weighted avg       0.45      0.43      0.44        93\n","\n"]}],"source":["import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.vgg19 import VGG19\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.metrics import classification_report\n","\n","# Define the data directories\n","train_dir = '/content/drive/MyDrive/Final/Train'\n","val_dir = '/content/drive/MyDrive/Final/Validation'\n","test_dir = '/content/drive/MyDrive/Final/Test'\n","\n","# Define the image size and batch size\n","img_size = (224, 224)\n","batch_size = 32\n","\n","# Define the data generators\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=img_size,\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","val_generator = val_datagen.flow_from_directory(\n","    val_dir,\n","    target_size=img_size,\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=img_size,\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","# Load the pre-trained VGG19 model\n","vgg = VGG19(include_top=False, weights='imagenet', input_shape=(img_size[0], img_size[1], 3))\n","\n","# Freeze the layers\n","for layer in vgg.layers:\n","    layer.trainable = False\n","\n","# Add new layers\n","x = Flatten()(vgg.output)\n","x = Dense(1024, activation='relu')(x)\n","x = Dense(512, activation='relu')(x)\n","x = Dense(4, activation='softmax')(x)\n","\n","# Create the model\n","model = Model(inputs=vgg.input, outputs=x)\n","\n","# Compile the model\n","model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(\n","    train_generator,\n","    epochs=10,\n","    validation_data=val_generator)\n","\n","# Evaluate the model on the test set\n","test_loss, test_acc = model.evaluate(test_generator)\n","print('Test loss:', test_loss)\n","print('Test accuracy:', test_acc)\n","\n","# Get the predicted classes for the test set\n","y_pred = model.predict(test_generator)\n","y_pred = np.argmax(y_pred, axis=1)\n","\n","# Get the true classes for the test set\n","y_true = test_generator.classes\n","\n","# Print the classification report\n","target_names = list(test_generator.class_indices.keys())\n","print(classification_report(y_true, y_pred, target_names=target_names))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":961,"status":"ok","timestamp":1684850123859,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"QephJksv5ISd","outputId":"51b888a2-75b0-4f89-822a-edbb0f63c2d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'Brvo': 0, 'Crvo': 1, 'Normal': 2, 'Rao': 3}\n","{'Brvo': 0, 'Crvo': 1, 'Normal': 2, 'Rao': 3}\n","{'Brvo': 0, 'Crvo': 1, 'Normal': 2, 'Rao': 3}\n"]}],"source":["print(train_generator.class_indices)\n","print(val_generator.class_indices)\n","print(test_generator.class_indices)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5156343,"status":"ok","timestamp":1684855447414,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"Z9rraIkg5xnd","outputId":"64694c47-b159-484b-d0cf-3395ac5e2729"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 695 images belonging to 4 classes.\n","Found 91 images belonging to 4 classes.\n","Found 93 images belonging to 4 classes.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","22/22 [==============================] - 506s 23s/step - loss: 4.6246 - accuracy: 0.4691 - val_loss: 1.7344 - val_accuracy: 0.5824\n","Epoch 2/10\n","22/22 [==============================] - 474s 22s/step - loss: 0.7656 - accuracy: 0.7223 - val_loss: 0.4431 - val_accuracy: 0.8791\n","Epoch 3/10\n","22/22 [==============================] - 476s 22s/step - loss: 0.3760 - accuracy: 0.8705 - val_loss: 0.5964 - val_accuracy: 0.6923\n","Epoch 4/10\n","22/22 [==============================] - 502s 23s/step - loss: 0.3001 - accuracy: 0.8748 - val_loss: 0.4226 - val_accuracy: 0.9011\n","Epoch 5/10\n","22/22 [==============================] - 501s 23s/step - loss: 0.2210 - accuracy: 0.9209 - val_loss: 0.3932 - val_accuracy: 0.8791\n","Epoch 6/10\n","22/22 [==============================] - 462s 21s/step - loss: 0.2240 - accuracy: 0.9237 - val_loss: 0.3542 - val_accuracy: 0.9231\n","Epoch 7/10\n","22/22 [==============================] - 478s 22s/step - loss: 0.1481 - accuracy: 0.9496 - val_loss: 0.3548 - val_accuracy: 0.8791\n","Epoch 8/10\n","22/22 [==============================] - 501s 23s/step - loss: 0.1679 - accuracy: 0.9424 - val_loss: 0.3209 - val_accuracy: 0.9341\n","Epoch 9/10\n","22/22 [==============================] - 508s 23s/step - loss: 0.1079 - accuracy: 0.9583 - val_loss: 0.4949 - val_accuracy: 0.7363\n","Epoch 10/10\n","22/22 [==============================] - 497s 23s/step - loss: 0.0907 - accuracy: 0.9669 - val_loss: 0.3515 - val_accuracy: 0.9011\n","3/3 [==============================] - 56s 19s/step - loss: 0.4988 - accuracy: 0.8280\n","Test loss: 0.4987737238407135\n","Test accuracy: 0.8279569745063782\n"]}],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.vgg19 import VGG19\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","\n","# Define the data directories\n","train_dir = '/content/drive/MyDrive/Final/Train'\n","val_dir = '/content/drive/MyDrive/Final/Validation'\n","test_dir = '/content/drive/MyDrive/Final/Test'\n","\n","# Define the image size and batch size\n","img_size = (224, 224)\n","batch_size = 32\n","\n","# Define the data generators\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=img_size,\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","val_generator = val_datagen.flow_from_directory(\n","    val_dir,\n","    target_size=img_size,\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=img_size,\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","# Define the model\n","vgg = VGG19(include_top=False, weights='imagenet', input_shape=(img_size[0], img_size[1], 3))\n","\n","# Freeze the layers\n","for layer in vgg.layers:\n","    layer.trainable = False\n","\n","# Add new layers\n","x = Flatten()(vgg.output)\n","x = Dense(1024, activation='relu')(x)\n","x = Dense(512, activation='relu')(x)\n","x = Dense(4, activation='softmax')(x)\n","\n","# Create the model\n","model = Model(inputs=vgg.input, outputs=x)\n","\n","# Compile the model\n","model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(\n","    train_generator,\n","    epochs=10,\n","    validation_data=val_generator)\n","\n","# Evaluate the model on the test set\n","test_loss, test_acc = model.evaluate(test_generator)\n","print('Test loss:', test_loss)\n","print('Test accuracy:', test_acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182},"executionInfo":{"elapsed":4162,"status":"error","timestamp":1687195481288,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"B0FtK_ggPThH","outputId":"706766f5-157f-4b29-c50a-8682f96d00de"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-a112bbc24ab3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Final/Project.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["from tensorflow.keras.models import load_model\n","model.save('/content/drive/MyDrive/Final/Project.h5')"]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.models import load_model\n","import cv2\n","import numpy as np\n","\n","# Load the trained model\n","model = load_model('/content/drive/MyDrive/Final/Project.h5')\n","\n","# Define the classes\n","classes = ['BRVO', 'CRVO', 'NORMAL', 'RAO']\n","\n","\n","# Load and preprocess the image\n","img_path = '/content/drive/MyDrive/Final/Test/Crvo/1115_aug0.png'\n","img = load_img(img_path, target_size=(224, 224), color_mode='grayscale')\n","img = img_to_array(img)\n","\n","# Convert image to uint8\n","img = img.astype(np.uint8)\n","\n","# Apply CLAHE to enhance contrast\n","clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n","img = clahe.apply(img)\n","\n","# Convert the image to RGB\n","img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n","\n","# Reshape and expand dimensions\n","img_rgb = img_rgb.reshape(224, 224, 3)\n","img_rgb = np.expand_dims(img_rgb, axis=0)\n","\n","# Make a prediction\n","pred = model.predict(img_rgb)\n","pred_class = np.argmax(pred, axis=1)\n","pred_class = classes[pred_class[0]]\n","print(\"DISEASE IS:\", pred_class)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rVsPo-Xq6C8m","executionInfo":{"status":"ok","timestamp":1687316781488,"user_tz":-330,"elapsed":10095,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"}},"outputId":"5eb0f6bc-4387-4026-9f0e-ef8dce5e784b"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 865ms/step\n","DISEASE IS: CRVO\n"]}]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12518,"status":"ok","timestamp":1687314714043,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"__9dmSEx52Tq","outputId":"58451303-5575-48b1-90df-1de9324368ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (5.5.6)\n","Collecting ipykernel\n","  Downloading ipykernel-6.23.2-py3-none-any.whl (152 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting comm>=0.1.1 (from ipykernel)\n","  Downloading comm-0.1.3-py3-none-any.whl (6.6 kB)\n","Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (1.6.6)\n","Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (7.34.0)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.1.12)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.3.0)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (0.1.6)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel) (1.5.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ipykernel) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.9.5)\n","Requirement already satisfied: pyzmq>=20 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (23.2.1)\n","Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.3.1)\n","Requirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.7.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (67.7.2)\n","Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel)\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (3.0.38)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (2.14.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (4.8.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (3.3.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel) (0.2.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n","Installing collected packages: jedi, comm, ipykernel\n","  Attempting uninstall: ipykernel\n","    Found existing installation: ipykernel 5.5.6\n","    Uninstalling ipykernel-5.5.6:\n","      Successfully uninstalled ipykernel-5.5.6\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.23.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed comm-0.1.3 ipykernel-6.23.2 jedi-0.18.2\n"]}],"source":["!pip install -U ipykernel"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6083,"status":"ok","timestamp":1687314004523,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"IVOmx1Yr52Hp"},"outputs":[],"source":["!pip install -q streamlit"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7409,"status":"ok","timestamp":1687314015722,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"0_q2R__W51zo","outputId":"406a1f9f-9c6b-44b0-d5bb-5a0dbd516a09"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (6.0.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0)\n"]}],"source":["!pip install pyngrok"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":562,"status":"ok","timestamp":1687314089384,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"JxxCMxBz9rMN"},"outputs":[],"source":["from pyngrok import ngrok\n","\n","ngrok.set_auth_token('2QF2bVPy0DKSqLAfxXVzFvSuAz6_5zFcnXGST8g58wo9paaHN')"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":775,"status":"ok","timestamp":1687315088060,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"0nX4AVPL96uR","outputId":"4a5fe28f-b51c-44aa-f089-9223a90bee82"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting score.py\n"]}],"source":["%%writefile score.py\n","\n","import tensorflow as tf\n","import numpy as np\n","import streamlit as st\n","from PIL import Image, ImageOps\n","\n","\n","st.title(\"Retinal Occlusion Classification\")\n","st.text(\"Upload the fundus image for image classification\")\n","\n","#st.set_option('deprecation.showfileUploaderEncoding', False)\n","@st.cache(allow_output_mutation=True)\n","def load_model():\n","  model=tf.keras.models.load_model('/content/drive/MyDrive/Final/Project.h5')\n","  return model\n","\n","with st.spinner('Loading model into memory...'):\n","  model=load_model()\n","\n","# Define the classes\n","classes = ['BRVO', 'CRVO', 'NORMAL', 'RAO']\n","\n","# Select an image file using Streamlit file uploader\n","uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n","\n","\n","if uploaded_file is not None:\n","  # Open the uploaded image using PIL\n","  pil_image = Image.open(uploaded_file)\n","  st.image(pil_image, use_column_width=True)\n","  size=(224,224)\n","  image=ImageOps.fit(pil_image, size, Image.ANTIALIAS)\n","  img=np.asarray(image)\n","  img_reshape = img[np.newaxis,...]\n","\n","  # Reshape and expand dimensions\n","  img_rgb = img_reshape.reshape(224, 224, 3)\n","  img_rgb = np.expand_dims(img_rgb, axis=0)\n","\n","\n","  st.write(\"Predicted class: \")\n","  with st.spinner('classifying...'):\n","    pred = model.predict(img_rgb)\n","    pred_class = np.argmax(pred, axis=1)\n","    pred_class = classes[pred_class[0]]\n","    st.write(pred_class)\n","\n","  st.write(\"\")\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":474,"status":"ok","timestamp":1687314098007,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"MUitIw1HJmRC","outputId":"adf988c1-4e65-4e98-d624-8c513ada4444"},"outputs":[{"output_type":"stream","name":"stdout","text":["nohup: appending output to 'nohup.out'\n"]}],"source":["!nohup streamlit run score.py &"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cze7223oJ1xf","executionInfo":{"status":"ok","timestamp":1687314103258,"user_tz":-330,"elapsed":2339,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"}},"outputId":"061b1018-7463-44e4-aaeb-a0116269a926"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n","\u001b[0m\n","2023-06-21 02:21:40.812 Port 8501 is already in use\n"]}],"source":["from pyngrok import ngrok\n","\n","# Assuming you have a web application running on port 8501\n","!streamlit run --server.port 8501 score.py &\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":503,"status":"ok","timestamp":1687314107599,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"_6d6h_ksMpFV","outputId":"edbb11e3-d272-460c-cb25-46a5521f5cff"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:pyngrok.process.ngrok:t=2023-06-21T02:21:45+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"]}],"source":["# Connect ngrok to the port where your local server is running\n","ngrok_tunnel = ngrok.connect(8501)\n","\n","# Get the public URL\n","public_url = ngrok_tunnel.public_url\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1687314110180,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"C_roXmv-MuWV","outputId":"c0275c02-114f-4540-ec6b-45dea94440d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Public URL: https://98cb-34-83-39-209.ngrok-free.app\n"]}],"source":["print(\"Public URL:\", public_url)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":723,"status":"ok","timestamp":1687314114171,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"Fm0-cRE8NEqh","outputId":"61e6b9ca-f0db-42a5-a781-a5708e218609"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n","\n","\n","  You can now view your Streamlit app in your browser.\n","\n","  Network URL: http://172.28.0.12:8502\n","  External URL: http://34.83.39.209:8502\n","\n","  Stopping...\n","\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n","\n","\n","  You can now view your Streamlit app in your browser.\n","\n","  Network URL: http://172.28.0.12:8501\n","  External URL: http://34.83.39.209:8501\n","\n"]}],"source":["!cat nohup.out"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6577,"status":"ok","timestamp":1685774995080,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"7Cr5V4U6K9Yh","outputId":"2f32c199-d57c-42e8-c2bf-c46ff7390ce6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (6.0.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0)\n"]}],"source":["!pip install pyngrok"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1685774999255,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"FDoHr6o2K9Ur","outputId":"4d3df206-5659-442b-b55a-d13ebf553022"},"outputs":[{"name":"stdout","output_type":"stream","text":["1265\n"]}],"source":["!pgrep ngrok"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10885,"status":"ok","timestamp":1685775018461,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"PkOPthhgK9Q6","outputId":"cf8e6466-e6b1-4fc8-ef44-23c530a92b7e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ngrok\n","  Downloading ngrok-0.8.1-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (6.0.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0)\n","Installing collected packages: ngrok\n","Successfully installed ngrok-0.8.1\n"]}],"source":["!pip install --upgrade ngrok pyngrok"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":632,"status":"ok","timestamp":1685774970573,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"qe20bVdiK9O_","outputId":"41e61b93-3871-4ddc-b7ea-cacdda11b0c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["NAME:\n","  http - start an HTTP tunnel\n","\n","USAGE:\n","  ngrok http [address:port | port] [flags]\n","\n","DESCRIPTION: \n","  Starts a tunnel listening for HTTP/HTTPS traffic with a specific hostname.\n","  The HTTP Host header on incoming public requests is inspected to\n","  determine which tunnel it matches.\n","\n","  HTTPS endpoints terminate TLS traffic at the ngrok server using the\n","  appropriate certificates. The decrypted, HTTP traffic is then forwarded\n","  through the secure tunnel and then to your local server. If you don't want\n","  your TLS traffic to terminate at the ngrok server, use a TLS or TCP tunnel.\n","\n","TERMS OF SERVICE: https://ngrok.com/tos\n","\n","EXAMPLES: \n","  ngrok http 8080                             # forward ngrok subdomain to port 80\n","  ngrok http example.com:9000                 # forward traffic to example.com:9000\n","  ngrok http --domain=bar.ngrok.dev 80        # request subdomain name: 'bar.ngrok.dev'\n","  ngrok http --domain=example.com 1234        # request tunnel 'example.com' (DNS CNAME)\n","  ngrok http --basic-auth='falken:joshua' 80  # enforce basic auth on tunnel endpoint\n","  ngrok http --host-header=example.com 80     # rewrite the Host header to 'example.com'\n","  ngrok http file:///var/log                  # serve local files in /var/log\n","  ngrok http https://localhost:8443           # forward to a local https server\n","\n","OPTIONS:\n","      --authtoken string                 ngrok.com authtoken identifying a user\n","      --basic-auth strings               enforce basic auth on tunnel endpoint, 'user:password'\n","      --cidr-allow strings               reject connections that do not match the given CIDRs\n","      --cidr-deny strings                reject connections that match the given CIDRs\n","      --circuit-breaker float            reject requests when 5XX responses exceed this ratio\n","      --compression                      gzip compress http responses from your web service\n","      --config strings                   path to config files; they are merged if multiple\n","      --domain string                    host tunnel on a custom subdomain or hostname (requires DNS CNAME)\n","  -h, --help                             help for http\n","      --host-header string               set Host header; if 'rewrite' use local address hostname\n","      --inspect                          enable/disable http introspection (default true) (default <nil>)\n","      --log string                       path to log file, 'stdout', 'stderr' or 'false' (default \"false\")\n","      --log-format string                log record format: 'term', 'logfmt', 'json' (default \"term\")\n","      --log-level string                 logging level: 'debug', 'info', 'warn', 'error', 'crit' (default \"info\")\n","      --mutual-tls-cas string            path to TLS certificate authority to verify client certs in mutual tls\n","      --oauth string                     enforce authentication oauth provider on tunnel endpoint, e.g. 'google'\n","      --oauth-allow-domain strings       allow only oauth users with these email domains\n","      --oauth-allow-email strings        allow only oauth users with these emails\n","      --oauth-client-id string           oauth app client id, optional\n","      --oauth-client-secret string       oauth app client secret, optional\n","      --oauth-scope strings              request these oauth scopes when users authenticate\n","      --oidc string                      oidc issuer url, e.g. https://accounts.google.com\n","      --oidc-client-id string            oidc app client id\n","      --oidc-client-secret string        oidc app client secret\n","      --oidc-scope strings               request these oidc scopes when users authenticate\n","      --proxy-proto string               version of proxy proto to use with this tunnel, empty if not using\n","      --region string                    ngrok server region [us, eu, au, ap, sa, jp, in] (default \"us\")\n","      --request-header-add strings       header key:value to add to request\n","      --request-header-remove strings    header field to remove from request if present\n","      --response-header-add strings      header key:value to add to response\n","      --response-header-remove strings   header field to remove from response if present\n","      --scheme strings                   which schemes to listen on (default [https])\n","      --verify-webhook string            validate webhooks are signed by this provider, e.g. 'slack'\n","      --verify-webhook-secret string     secret used by provider to sign webhooks, if any\n","      --websocket-tcp-converter          convert ingress websocket connections to TCP upstream\n","\n","ERROR:  authentication failed: Your account is limited to 1 simultaneous ngrok agent session.\n","ERROR:  You can run multiple tunnels on a single agent session using a configuration file.\n","ERROR:  To learn more, see https://ngrok.com/docs/ngrok-agent/config/\n","ERROR:  \n","ERROR:  Active ngrok agent sessions in region 'us':\n","ERROR:    - ts_2QgUmnP0Onyk0pmrd25TRfVDMXT (34.125.234.32)\r\n","ERROR:  \r\n","ERROR:  ERR_NGROK_108\r\n","ERROR:  \n"]}],"source":["!ngrok http 8501"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16906,"status":"ok","timestamp":1684934164081,"user":{"displayName":"GRACE MARIA BINU B.Tech CSE A 2019-2023","userId":"07356324124085547197"},"user_tz":-330},"id":"nQno6Y-uPZz8","outputId":"54e9a40b-4028-444d-e601-76d0d9a9cb0f"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 1s 1s/step\n","DISEASE IS: CRVO\n"]}],"source":["from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.models import load_model\n","import cv2\n","import numpy as np\n","\n","# Load the trained model\n","model = load_model('/content/drive/MyDrive/Final/Project.h5')\n","\n","# Define the classes\n","classes = ['BRVO', 'CRVO', 'NORMAL', 'RAO']\n","\n","\n","# Load and preprocess the image\n","img_path = '/content/913_aug1.png'\n","img = load_img(img_path, target_size=(224, 224), color_mode='grayscale')\n","img = img_to_array(img)\n","\n","# Convert image to uint8\n","img = img.astype(np.uint8)\n","\n","# Apply CLAHE to enhance contrast\n","clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n","img = clahe.apply(img)\n","\n","# Convert the image to RGB\n","img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n","\n","# Reshape and expand dimensions\n","img_rgb = img_rgb.reshape(224, 224, 3)\n","img_rgb = np.expand_dims(img_rgb, axis=0)\n","\n","# Make a prediction\n","pred = model.predict(img_rgb)\n","pred_class = np.argmax(pred, axis=1)\n","pred_class = classes[pred_class[0]]\n","print(\"DISEASE IS:\", pred_class)\n"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1BtdUIXv4Nhs_giKYC1OevWkfUzOilNaO","authorship_tag":"ABX9TyN46YXp8pgCkQmNg9AuM3q3"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}